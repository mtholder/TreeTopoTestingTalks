\documentclass[11pt]{article}
\usepackage{graphicx}
\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}

\textwidth = 6.5 in
\textheight = 9 in
\oddsidemargin = 0.0 in
\evensidemargin = 0.0 in
\topmargin = 0.0 in
\headheight = 0.0 in
\headsep = 0.0 in
\parskip = 0.2in
\parindent = 0.0in
\usepackage{paralist} %compactenum

%\newtheorem{theorem}{Theorem}
%\newtheorem{corollary}[theorem]{Corollary}
%\newtheorem{definition}{Definition}
\usepackage{tipa}
\usepackage{amsfonts}
\usepackage[mathscr]{eucal}

% Use the natbib package for the bibliography
\usepackage[round]{natbib}
\bibliographystyle{apalike}
\newcommand{\exampleMacro}[1]{\mu_{#1}}

\title{An annotated bibliography to frequentist topology testing}
\author{Mark T. Holder}

\usepackage{xspace}
%\usepackage{ulem}
\usepackage{url}
\usepackage{hyperref}
\hypersetup{backref,  pdfpagemode=FullScreen,  linkcolor=blue, citecolor=red, colorlinks=true, hyperindex=true}

\newcommand{\boot}[1]{X^{(#1)}}
\newcommand{\sdLL}[1]{\hat{\sigma_{#1}}}
\newcommand{\sdLLBoot}[2]{\hat{\sigma_{#1}}^{(#2)}}
\newcommand{\like}{\ell}
\newcommand{\expectation}{{\mathbb{E}}}
\newcommand{\pvalue}{$P$-value\xspace}
\newcommand{\pvalues}{$P$-values\xspace}
\begin{document}
\maketitle

Notation:
\begin{itemize}
	\item $M$ characters, sites, or columns;
	\item $N$ leaves, taxa, or sequences;
	\item $K$ plausible trees to be tested;
	\item $B$ bootstrap replicates;
	\item $\delta$ difference in log-likelihood between trees
	\item $\like(\theta_i,T_i|X)$ is the likelihood of the tree $i$ and the numerical parameters $\theta_i$ given the data (proportional to $\Pr(X|\theta_i,T_i)$
	\item $\ln L(\theta_i,T_i|X)$ is the log-likelihood of the tree $i$ and the numerical parameters $\theta_i$ given the data (proportional to $\Pr(X|\theta_i,T_i)$
	\item $\sdLL{i}$ is the standard deviation of the log-likelihoods for $\theta_i,T_i$.
	\item $\sdLLBoot{i}{j}$ is the standard deviation of the log-likelihoods for $\theta_i,T_i$ computed on bootstrap replicate $j$.
\end{itemize}
	

\citet{Cavender1978}:  Citation for Cavender part of CFN model.  Defines rejection regions based on low probability of observing the data patterns.  Focusses on regions of pattern count space (for four taxa) in which the parsimony score of the best tree is at least $r$ steps better than the next best tree.  Table 2 (page 277) shows the critical value of $r$ needed to assure various $\alpha$ values.  For $\alpha= 0.05$ you have the depressing:
\begin{center}
\begin{tabular}{cccccccc}
$M$ & 3 & 4 & 10 & 15 & 20 & 30 & 40 \\
$r$ & 2 & 3 & 5 & 7 & 9 & 13 & 15 
\end{tabular}
\end{center}
Notes that $\Pr$ conflicting synapomorphy can be as high as 1/4 (and as high as the probability of the true synapomorphy).  He notes that this test is not ``locally most powerful'' nor is it unbiased. Points out that you can estimate the tree if you don't know the number of constant characters (p278; relevant to the Mkv model of \citep{Lewis2001}).

\citet{Felsenstein1985}: Introduces the bootstrap to phylogenetics.
p784 - use of columns as justifiable.\\
p786 - test of monophyly of a clade.  Reject the alternatives if they occur is <5\% of bootstrap estimates.\\
p786 - does not correct for inconsistency rather ``a confidence interval within which is contained not the true phylogeny, but the phylogeny that would be estimated on repeated sampling''\\
p787 - multiple tests problem and need to correct for it.\\
p787 - difficulties caused by tree space. \\
p787 - delete 1/2 jackknife \\
p788 - use of pattern weights to implement bootstrapping. \\
p790 - perfect Hennigian data, "rule of three" and discussion of connection to clean data and random support around a trifurcation.

\citet{GautL1995}: Simulation study of ML inference and LRT in the four-taxon case.  ML tree estimation is found to be robust to modeling errors. The authors compare the distribution of the LRT to the $\chi_1^2$ and find that they do not match (they mention the possibility of using a mixture of $\chi^2$, but also cite Thompson via pers comm to \citep{Felsenstein1988} that this may not be a problem in this context because the likelihood is continuous over the trifurcation).
LRT using $\chi_1^2$ would reject too often if the model is too simple.


\citet{Sanderson1995}: Extensive discussion of objections to bootstapping centered around independence of samples and difficulties with defining a universe of characters to sample from.
        
pp313-315 provide a nice discussion of objections to Neyman-Pearson hypothesis testing in general.      

\citet{HuelsenbeckHN1996}: Introduce a likelihood-ratio test for monophyly in which monophyly is the null.  The test statistic is $\delta$, the difference in log-likelihoods for the ML subject to the constraint of monophyly and the ML tree found under no constraints. 
Significance is assessed using the parametric bootstrap.
They note that the parametric bootstrap is prone to overconfidence when the model used to generate the data is too simple.

\citet{GoldmanAR2000}: Very clear discussion of the selection bias problem in most uses of the KH-test and survey of the tests up to that point. They introduce a cumbersome scheme of mnemonics:
\begin{compactitem}
	\item a \underline{pri}ori $|$ \underline{pos}teriori selection of candidates
	\item \underline{N}on\underline{P}arametric $|$ \underline{P}arametric
	\item \underline{f}ull $|$ \underline{p}artial $|$ \underline{n}o optimization of parameters on bootstrap reps.
	\item \underline{c}entered $|$ \underline{u}ncentered
	\item compare attained $\delta$ to null distribution: \underline{d}irectly $|$ using \underline{n}ormality assumption $|$ \underline{a}dditional normal assumptions ($\hat{\delta}$ estimated from the sitewise $\delta(m)$ values) $|$ \underline{s}tronger assumption that the sitewise $\delta(m)$ are normally distributed.
\end{compactitem}

Pg 660 clear description of the SH test:
\begin{enumerate}
	\item Calculate the test statistic for each tree: $\delta_i = \ln L(\hat\theta,\hat{T}|X) - \ln L(\hat\theta_i, T_i|X)$
	\item for each bootstrap rep $1 \leq j \leq B$:
	\begin{enumerate}
		\item Calculate and store $t_i^{(j)} = \ln L(\hat\theta_i, T_i|\boot{j})$
	\end{enumerate}
	\item For each tree calculate the centering offset: $$\bar{t_i} = (1/B)\sum_{j=1}^Bt_i^{(j)}$$
	\item For each tree $i$ and stored bootstrap result $j$ calculate: ${c_i^{(j)}} = t_i^{(j)} - \bar{t_i}$
	\item For each bootstrap rep $1 \leq j \leq B$ find the largest likelihood relative to the mean for the tree: $c^{(j)} = \max\left[c_i^{(j)}\right] \mbox{ over all } i$
	\item \pvalue for $T_i\approx$ the fraction of reps for which $c^{(j)} > \delta_i$
\end{enumerate}

Point out (pp661) that if an incorrect (a posteriori) KH test is not significant, then the correct SH test won't reject either.


\citet{BerryGC2000}: follows the decision-theoretic framework of \citet{BerryG1996} but uses a quartet-distance as a measure of distance from the true tree. A fully-resolved tree is constructed and then poorly supported branches are collapsed.

\citet{BilleraHV2001}: describe a geometric approach to tree-space that enables a metric distance that can be used to find centroid trees from a collection of trees (e.g. in summarizing bootstrap results).

\citet{ArisBrosou2003}: Discuss the fact that the plethora of tests and differing \pvalues often reflect differing nulls.  Discusses a ``natural'' null is that the $k$ trees are equidistance from the unknown, true distribution ($\mu$); thus $\expectation_{\mu}(\like(\theta_1,T_1|X) = \expectation_{\mu}\{\like(\theta_K,T_K|X)\}$ for all trees in the null.  Introduces two means of reducing the composite hypothesis over trees to a simple hypothesis.
In his frequentist significance test (FST), the mean of the maximized log likelihoods is used as $$h_{0,\tau}(X) = (1/K)\sum_{i=1}^K \like(\hat{\theta_i},T_i|X)$$
resulting in a test like the SH test.

In the frequentist hypothesis test (FHT) the ML tree is used to calculate $h_{0,\tau}(X)$; he argues that this make it similar to the bootstrap.

Argues that FST is geared toward identifying a set of ``close'' trees; while FHT tries to identify the true tree.

Analysis of real data points to underparameterization of the available models, and leads to a recommendation to adopt conservative tests.
AU test showed sensitivity to model mis-specification but still found to be ``safer'' than other hypothesis tests.

In both cases, the algorithm then consists of the following:
\begin{enumerate}
	\item For each tree: $\hat{v}_i = \like(\theta_i,T_i|X) - h_{0,\tau}(X)$
	\item Calculate the test statistic for each tree: $t_i = \hat{v}_i/\sdLL{i}$
	\item for each bootstrap rep $j$:
	\begin{enumerate}
		\item $s_i^{(j)} = \left(\hat{v}_i^{(j)} - \hat{v}_i \right)/\sdLLBoot{i}{j}$
		\item $\hat{s}^{(j)} = \min\left[{s_i^{(j)}}\right] \mbox{ over all } i\leq K$
	\end{enumerate}
	\item \pvalue for $T_i\approx$ the fraction of reps for which $\hat{s}^{(j)} < t_i$
\end{enumerate}

This is similar to SH, except the test-statistic rather than the resampling is centered.

\citet{ArisBrosou2003b}: A Bayesian version of the methods introduced in \citet{ArisBrosou2003} where the posterior is weight trees in the reduction from complex  to simple hypothesis.

\citet{ErixonSBO2003}: Simulation study comparing BP to posterior probabilities under the same model.
Find posteriors to be sensitive to model misspecification (high Type I error).

BP tended to be lower than posterior probabilities, and both were lower than the probability of reconstructing the tree given  more data (but they did not sweep over branch length space).


\citet{Galtier2004}: analytical and simulation study of the effect on extreme violation of the independence assumption (including repeating data patterns and mimicking the effect of pairing across an RNA stem).  Non-independence decrease accuracy of parsimony, but did not decrease BP.  ``Should we, therefore, worry about past and future interpretations of bootstrap scores? Probably not too much because the influence of nonindependence on the bootstrap score appears slight. The overestimation was always $<10\%$ in Figure 1.''  Consecutive-site {\em vs} dispersed bootstrap procedures were compared and suggested as a means of testing for the effect of non-independence in real analyses.

\citet{HuelsenbeckR2004}: show that posteriors behave as expected when the true parameters are drawn from the prior.  This paper focusses on Bayesian inference, but is relevant to the interpretation of other studies that examine whether or not BP can be used as $\Pr$ correct reconstruction.

\citet{AnisimovaG2006}: Approximate LRT for branches introduced. For testing a branch, $\delta$ is calculated by looking for best two ML scores among the three trees that resolve the polytomy created by collapsing the branch.

 $2\delta$ shown to follow $\frac{1}{2}\chi_0^2 + \frac{1}{2}\chi_1^2$ when null is known {\em a priori}.  But Bonferroni or ``cubic'' correction was needed to account for selection bias. For lower \pvalues, the Bonferroni correction is to conservative, and the cubic correction is:
\begin{eqnarray*}
	P  \approx 1 - (1-\alpha)^3 &\approx& 3\alpha + \mathcal{O}(\alpha^2)\\
	 &\approx& 1.5 - 1.5F_{\chi_1^2}(2\delta)
\end{eqnarray*}
where $F_{\chi_1^2}(2\delta)$ is the cumulative probability function for the $\chi_1^2$ evaluated at the LRT (which is 2$\delta$).
This implies that if $\delta > 2.25$, then \pvalue will be $<0.05$.


\begin{quote}
	``When the analysis model describes data well, the type I error rate obtained using Bonferroni corrected mixture distribution is close to the significance level $\alpha$, so that the standard LRT remains accurate. Moreover, our results suggest that minor (but detectable) deviations from model assumptions do not significantly affect its accuracy. However, when important factors (e.g., transition/transversion ratio, rate variation among sites) are not accounted for, the test can become very inaccurate.(p545)''
\end{quote}

They find 1-BP to be excessively liberal for some tree shapes. They attribute the difference to plotting Type-I error rates against $\alpha$ cutoffs conditionally on tree shape rather than $\Pr$ true branch vs cutoff binned by BP (which they find to differ based on simulation tree shape).

\citet{SvennbladdEOB2006}: Detailed discussion of how the Bayesian interpretation of BP given by \citet{EfronHH1996} does not correspond to a Bayesian phylogenetic analysis in which the prior is placed on tree/model parameters (rather than a uniform prior over pattern frequency space).
They also discuss how the set of {\em separately informative} data patterns is not the same for ML and Bayesian approaches (e.g. an {\tt{AACT}} pattern would support $12|34$ in a Bayesian context, even under JC, because of interactions between longer on which the changes can occur and the branch length priors). 

\citet{Wrobel2008}: Review of topology testing including BP and Bayesian clade posteriors.


\citet{Susko2009}: Examining the star-tree (which should correspond to an lfc), Susko shows that \citep[{\em contra}\xspace][]{EfronHH1996} the BP is not first-order correct.
Instead, it is conservative. 
The general approach is to look at the distribution of bootstrap scores from points generated at the star tree, and see how this distribution changes as $M$ increases.
If BP were first order correct then, for large $M$, the distribution should be uniform (such that $1-BP$ is uniform and gives the correct \pvalue for any $\alpha$). 
In fact, ``BP as large as $y$ arises less frequently than $y\times 100\%$ of the time.'' (p218).
Susko attributes this to the relevant lfc being a at a point where three topologies come together. 
The AU test returns less biased \pvalues, but they still do not satisfy first-order correctness.

\citet{AnisimovaGDDG2011}: survey of branch support. Simulate under K80+covarion and HKY+$\Gamma_4$ models.

\bibliography{topotesting}
 \end{document}  
