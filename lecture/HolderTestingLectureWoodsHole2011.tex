\documentclass[landscape]{foils} 
\input{../common-preamble-start}
\input{../preamble.tex}
\input{../common-preamble-end}
\usepackage{pdfpages}
\usepackage{bm}
\usepackage{ifsym}

\begin{document}

\myNewSlide
\huge 
Thanks to Paul Lewis, Joe Felsenstein, and Peter Beerli for slides.

\myNewSlide
\section*{Reasons phylogenetic inference might be wrong}
\Large
\begin{compactenum}
	\item Our data might be wrong (``garbage in garbage out'')
	\item {\em Systematic error} -- our inference method might not be sophisticated enough
	\item \underline{{\em Random error}} -- We might not have enough data, so we are misled by sampling error.
\end{compactenum}

(or it could be some combination of these).

\myNewSlide
\section*{Is our data set large enough to avoid random errors?}

This evening:
\begin{enumerate}
	\item Bootstrapping;
	\item Topology tests (KH, SH, AU, aLRT, aBayes, $\ldots$);
	\item Discussion of the theory underlying this plethora of testing methods, and the history of the debates around bootstrapping in phylogenetics;
	\item brief lab on how to use {\tt Seq-Gen} to conduct parametric bootstrapping.
\end{enumerate}


\myNewSlide
\includepdf[pages={1}]{../newimages/JoeFelsBootFig1.pdf} 

\myNewSlide
\includepdf[pages={1}]{../newimages/JoeFelsBootFig2.pdf} 

\myNewSlide
\includepdf[pages={1}]{../newimages/JoeFelsBootFig3.pdf} 
\myNewSlide
\begin{picture}(0,0)(0,0)
	  \put(0,-180){\makebox(0,0)[l]{\includegraphics[scale=1.2]{../newimages/hasegawaBootFigTree.pdf}}}
	  \put(0,-350){\small From Hasegawa's analysis of 232 sites D-loop}
\end{picture}

\myNewSlide
\section*{Bootstrapping for branch support}
\large
\begin{itemize}
	\item ``Rogue'' taxa can lower support for many splits -- you do not have to use the majority-rule consensus tree to summarize bootstrap confidence statements.
	\item Less thorough searching is faster, but will usually artificially lower BP. However, \citet{AnisimovaGDDG2011} report that RAxML's rapid bootstrap algorithm may inflate bootstrap proportions).
\end{itemize}


\myNewSlide
\large
\begin{picture}(500,0)(0,0)
	  \put(-200,-190){\makebox(0,0)[l]{\includegraphics[scale=1.0]{../newimages/JoeFelsTreeLRT1.pdf}}}
	  \put(250,-100){1. Should we calculate the LRT as:}
	  \put(280,-140){$\delta = 2\left[\ln L(t=\hat{t},T) - \ln L(t=0,T)\right]$}
	  \put(250,-180){? }
	  \put(250,-250){2. And can we use the $\chi_1^2$ distribution to}
	  \put(250,-290){get the critical value for $\delta$?}
\end{picture}

\myNewSlide
\begin{picture}(500,0)(0,0)
	  \put(-200,-190){\makebox(0,0)[l]{\includegraphics[scale=1.0]{../newimages/JoeFelsTreeLRT1.pdf}}}
	  \put(250,-100){1. Should we calculate the LRT as:}
	  \put(280,-140){$\delta = 2\left[\ln L(t=\hat{t},T) - \ln L(t=0,T)\right]$}
	  \put(250,-180){? {\bf \color{red}No. $t=0$ might not yield the best}}
	  \put(260,-220){\bf\color{red} alternative $\ln L$}
	  \put(250,-290){2. And can we use the $\chi_1^2$ distribution to}
	  \put(250,-330){get the critical value for $\delta$ ?}
	  \put(250,-370){{\bf \color{red}No. Constraining parameters}}
	  \put(260,-410){{\bf \color{red}at boundaries leads to a mixture}}
	  \put(260,-450){{\bf \color{red}such as: $\frac{1}{2}\chi_0^2 + \frac{1}{2}\chi_1^2$}}
	  \put(260,-490){\small See \citet{OtaWHSK2000}.}
\end{picture}

\myNewSlide
\begin{picture}(500,0)(0,0)
	  \put(-200,-190){\makebox(0,0)[l]{\includegraphics[scale=1.0]{../newimages/JoeFelsTreeLRT2.pdf}}}
\end{picture}


\myNewSlide
\normalsize
\bibliography{phylo}
\end{document}

\myNewSlide
\section*{Frequentist phylogenetic hypothesis testing?}
If we have a tree, $T_0$, in mind {\em a priori}, then how can we answer the question:

``Based on this data, should we reject the tree?'' 

Clearly if $\hat{T}\neq T_0$, then there is a possiblity that we should reject $T$.  

But how do we calculate a p-value?

\myNewSlide
\section*{Frequentist phylogenetic hypothesis testing? (cont)}
What is our test-statistic? {\color{red} Difference in support between the null tree and the preferred tree.}

How do we find the null-distribution for the test statistic? {\color{red} Simulation}

\myNewSlide
\includepdf[pages={2}]{../lec14Testing/images/polBremer.pdf} 

\myNewSlide
\section*{Testing 2 trees}
\Large
Test statistic: The difference in score, $\delta$, between two trees chosen {\em a priori}.

Null hypothesis: Both trees are equally good explanations of the truth.

\[E(\delta) = 0\]

Is $\delta$ so large that we reject the null?\\ What if $\delta=-9$, should we reject the null?

\myNewSlide
\includepdf[pages={1}]{images/hivarsitediff.pdf} 

\myNewSlide
\includepdf[pages={1}]{images/lowvarsitediff.pdf} 

\myNewSlide
\section*{Tests that treat the number of variable length characters as fixed}
\large
\begin{compactenum}
	\item Winning sites test (test the null that there is an equal probability of a site favoring tree 1 over tree 2)
	\item Templeton's test a version of Wilcoxon's rank sum test
\end{compactenum}
Robust, but not very powerful

\myNewSlide
\includepdf[pages={1}]{images/hivardist.pdf} 

\myNewSlide
\includepdf[pages={1}]{images/lowvardist.pdf} 

\myNewSlide
I could generate the last 4 slides because I made up (and hence knew) a variance.

How can we assess the strength of support if we do not know the variance of the generating process?



\myNewSlide
\section*{Parametric bootstrapping}
\begin{compactenum}
	\item Simulate a large number of data sets on $T_0$. On each dataset, $i$:
	\begin{compactenum}
		\item Search for the preferred tree, $\hat{T}^{(i)}$
		\item Search for the best tree that is consistent with the null hypothesis, $T_0^{(i)}$
		\item Let $z_0^{(i)}$ be the difference in score  between these trees for data set $i$
	\end{compactenum}
	\item See if the observed test statistic $z$ is in the $\alpha$\% tail of the distribution $\mathbf{z}_0$
\end{compactenum}

\myNewSlide
\includepdf[pages={1-2}]{images/gtr_i_g_sim_hist_data.pdf} 

\myNewSlide
Parametric bootstrapping is powerful, but can also be sensitive to the model chosen to generate the data.

\myNewSlide
\includepdf[pages={1-2}]{images/jc_sim_hist_data.pdf} 


\myNewSlide
\section*{Kishino Hasegawa Test}
\begin{compactenum}
	\item Several variants:
	\begin{compactenum}
		\item parametric - using a normal approximation
		\item non-parametric - using a bootstrapping
	\end{compactenum}
	\item Appropriate for testing the null hypothesis that two trees explain the data equally well.
	\item {\bf Both} trees for the test must be specified from prior knowledge.
	\item Use the site-to-site variation in $\delta$ to estimate the variance of a Normal distribution
	\item In the null the mean is 0
\end{compactenum}

\myNewSlide
\includepdf[pages={8}]{images/polTopoTests.pdf} 

\myNewSlide
\section*{Kishino Hasegawa Test (bootstrapping)}
Rather than assume a Normal distribution and estimate a variance, it is common to bootstrap the
data to generate a null distribution of the total difference in score between 2 trees.

Bootstrapping is resampling your data to mimic the variability in the process that generated the data.


\myNewSlide
\includepdf[pages={33-34}]{images/joeTesting.pdf} 

\myNewSlide
\section*{Kishino Hasegawa Test (bootstrapping - continued)}
Bootstrapping can give us a sense of the variability, but if the original data favored tree 1 isn't it very likely that the bootstrapped replicates will be more likely to support tree 1 than tree 2?

This does not sound like we are following our null that both trees are equally good.

Solution: we must center the bootstrapped differences in score.
\myNewSlide
\includepdf[pages={2}]{images/polTopoTests.pdf} 

\myNewSlide
\includepdf[pages={4-5}]{images/polTopoTests.pdf} 

\myNewSlide
\includepdf[pages={10}]{images/polTopoTests.pdf} 

\myNewSlide
\section*{SH Test}
\normalsize
\begin{compactenum}
	\item Calculate the difference in lnL between each tree and the ML tree. Call this $\delta_{i}$
	\item Score each tree in your set on each bootstrap pseudoreplicate data set (using full optimization or RELL)
	\item Center the set of scores for each tree - force each tree's the mean lnL to be 0.0 by subtraction.
	\item For each bootstrap replicate calculate the difference between the best centered lnL and each tree's lnL - this is the $\delta_{i,j}$ for tree $i$ and bootstrap replicate $j$.
	\item For each tree count the proportion of bootstrap replicates in which $\delta_{ij}$ is larger (more extreme) than $\delta_{i}$.  This is the p-value for the tree.
	\item Reject trees that have p-values below the significance level for your test.
\end{compactenum}

\myNewSlide
\includepdf[pages={4-7}]{images/polBoot.pdf} 
\end{document}     

\end{document}     

