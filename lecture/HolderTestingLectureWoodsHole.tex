\documentclass[landscape]{foils} 
\input{../common-preamble-start} 
\input{../preamble}
\usepackage{bm}
\usepackage{mathrsfs}
\input{../common-preamble-end}
\usepackage{pdfpages}
\usepackage{bm}

\begin{document}

\myNewSlide
\huge 
{\begin{center}Hypothesis testing and phylogenetics\end{center}}
\vskip 3cm
\large Woods Hole Workshop on Molecular Evolution, 2017\par 
\vskip 3cm
\normalsize
\normalsize
Mark T. Holder\\
University of Kansas\par 
\vskip 1cm
Thanks to Paul Lewis, Joe Felsenstein, and Peter Beerli for slides.

\myNewSlide
\section*{Motivation}
Pipeline of:\par
Data collection $\rightarrow$ Alignment $\rightarrow$ Model selction $\rightarrow$ Tree estimation

gives us a {\em point estimate} of the best tree.

This lecture/lab covers:
\begin{compactenum}
	\item How confident should we be that this tree is correct?
	\item Can we be confident in some aspects of the tree ({\em e.g.} some clades)?
	\item If our question of interest is about evolution of characters, can
		we answer that question despite our uncertainty about the tree?
\end{compactenum}


\myNewSlide
\section*{Conclusions 1 - confidence on trees}\large
\large
\begin{compactenum}
	\item Non-parametric bootstrapping proportions are useful, but a little hard to interpret  precisely.
	\begin{compactitem}
		\item Susko has and adjustment (``aBP``) so that $1 - aBP\approx P$-value for the hypothesis that a recovered branch is not present in the true tree. 
	\end{compactitem}
	\item ``How should we assign a $P$-value to tree hypothesis?'' is surprisingly complicated.
	\begin{compactitem}
		\item The Kishino-Hasegawa (KH-Test) can be used if you are comparing 2 trees specified {\em a priori}
		\item Shimodaira's approximately unbiased (AU-Test) should be used if you are comparing a set of trees.
	\end{compactitem}
\end{compactenum}

\myNewSlide
\section*{Conclusions 2 - confidence about evo.~hypotheses}
If $H_0$ is about the evolution of a trait:
\begin{compactenum}
	\item $P$-value must consider uncertainty of the tree:
	\begin{compactitem}
		\item can be large $P$ over confidence set of trees.
		\item Bayesian methods (covered tomorrow) enable prior predictive or posterior predictive $P$-values.
	\end{compactitem}
\end{compactenum}

\myNewSlide
\section*{Conclusions 3 - simulate your own null distributions}
(the focus of the lab)
\begin{compactenum}
	\item In phylogenetics we often have to simulate data to approximate $P$-values 
	\item Designing the simulations requires care to make a convincing argument.
\end{compactenum}

%\input{bootstrapping.tex}
\input{khtest.tex}
\input{shtest.tex}

\myNewSlide
\normalsize
\bibliography{phylo}

\end{document}



\myNewSlide
\section*{Reasons phylogenetic inference might be wrong}
\Large
\begin{compactenum}
	\item {\em Systematic error} -- Our inference method might not be sophisticated enough
	\item \underline{{\em Random error}} -- We might not have enough data --  we are misled by sampling error.
\end{compactenum}

(or it could be some combination of these).

{Focus of this lecture: {\bf How confident can we be in the trees/splits inferred by ML?}}

\myNewSlide
\begin{compactenum}
	\item Bootstrapping
	\item Putting $P$-values on trees:
	\begin{compactitem}
		\item KH Test, SH Test
		\item parametric bootstrapping,
		\item aLRT, aBayes,
		\item 1 - BP,
		\item AU and \citet{EfronHH1996} correction
		\item aBP
	\end{compactitem}
	\item More {\em caveats}
\end{compactenum}

\myNewSlide
\section*{Some resources related to this talk}
A \href{http://www.zotero.org/groups/confidence_statements_on_phylogenies}{Zotero Group} of papers related to topology testing on trees.

A \url{http://phylo.bio.ku.edu/woodshole/index.html} has the beginnings of an annotated bibliography and some other notes.

The source for all the documents for my talk are at:\\ {\normalsize \url{https://github.com/mtholder/TreeTopoTestingTalks} }\\
{\normalsize \url{https://github.com/mtholder/treeTestingDemo}}


\includepdf[pages={64-74}]{../../../bodega/HolderSotU.pdf} 









\myNewSlide
\section*{Parametric bootstrapping to generate the null distribution for the LR statistic}
\begin{enumerate}
	\item find the best tree and model pair that are consistent with the null,
	\item Simulate many datasets under the parameters of that model,
	\item Calculate $\delta^{(j)} = 2\left[\ln L (\hat{T}^{(j)} \mid  X^{(j)}) - \ln L (\hat{T}_{0}^{(j)} \mid  X^{(j)})\right]$ for each simulated dataset.
		\begin{compactitem}
			\item the $(j)$ is just an index for the simulated dataset,
			\item $\hat{T}_{0}^{(j)}$ is the tree under the null hypothesis for simulation replicate $j$
		\end{compactitem}
\end{enumerate}


\myNewSlide
\section*{Parametric bootstrapping}
This procedure is often referred to as SOWH test (in that form, the null tree is specified {\em a priori}).

\citet{HuelsenbeckHN1996} describes how to use the approach as a test for monophyly.

Intuitive and powerful, but not robust to model violation \citep{Buckley2002}.

Can be done manually\footnote{instructions in \url{https://molevol.mbl.edu/index.php/ParametricBootstrappingLab}}
or via \href{https://github.com/josephryan/sowhat}{SOWHAT} by \citet{SOWHAT}. Optional demo \href{https://molevol.mbl.edu/index.php/SOWHAT}{here}.

\citet{Susko2014}: collapse optimize null tree with 0-length contraints for the branch in question (to avoid rejecting too often)

\myNewSlide
\includepdf[pages={1}]{/home/mtholder/Documents/ku_teaching/BIOL-848-2013/images/gtr_i_g_sim_hist_data.pdf} 


\myNewSlide
\includepdf[pages={1}]{/home/mtholder/Documents/ku_teaching/BIOL-848-2013/images/jc_sim_hist_data.pdf} 

\myNewSlide
\section*{aLRT of \citet{AnisimovaG2006}}
\begin{compactitem}
	\item For a {\bf branch} $j$, calculate $\delta_{j}^{\dag}$ as twice the difference in $\ln L$ between the optimal tree (which has the branch) and the best NNI neighbor.
	\item This is very fast.
	\item They argue that the null distribution for each LRT around the polytomy follows a $\frac{1}{2}\chi_0^2 + \frac{1}{2}\chi_1^2$ distribution
	\item The introduce Bonferroni-correction appropriate for correcting for the selection of the best of the three resolutions.
	\item They find aLRT to be accurate and powerful in simulations, but \citet{AnisimovaGDDG2011} report that it rejects too often and is sensitive to model violation.
\end{compactitem}

\myNewSlide
\begin{picture}(500,0)(0,0)
	  \put(-130,-450){\makebox(0,0)[l]{\includegraphics[scale=1.5]{../newimages/AnisimovaG2006Fig1.pdf}}}
	  \put(300,-200){aLRT = $2\left[\ln \ell_1 - \ln L(T_2 \mid X)\right]$}
	  \put(300,-240){$\ell_1 = L(T_1 \mid X)$}
	  \put(400,-400){\small Image from \citet{AnisimovaG2006}}
\end{picture}

\myNewSlide
\section*{aBayes \citet{AnisimovaGDDG2011} }


$$\mbox{aBayes}(T_1 \mid X) = \frac{\Pr(X \mid T_1)}{\Pr(X \mid T_1) + \Pr(X \mid T_2) + \Pr(X \mid T_3)}$$

Simulation studies of \citet{AnisimovaGDDG2011} show it to have the best power of the methods that do not have inflated probability of falsely rejecting the null.

It is sensitive to model violation.

This is similar to ``likelihood-mapping'' of \citet{StrimmerVH1997}


\myNewSlide
\section*{aLRT and aBayes in Pattern Frequency Space}
\begin{picture}(-0,0)(-0,0)
	\put(10,-120){\makebox(30,-190)[l]{\includegraphics[scale=1.]{../newimages/simple-treespace-ppv2.pdf}}}
	\put(-50,-0){In aLRT, we use mixtures of $\chi^2$}
	\put(-40,-30){and selection bias corrections}
	\put(-40,-60){to calculate the $P$-value.}
	\put(370,-0){In aBayes, we normalize}
	\put(380,-30){the ML scores to sum to 1}
\end{picture}


\myNewSlide
\section*{Summary - Part 1}

\begin{itemize}
	\item $\delta(T_1,T_2 \mid X) = 2\left[\ln L(T_1 \mid X) - \ln L(T_2 \mid X)\right]$ is a powerful statistic for discrimination between trees.
	\item We can assess confidence by considering the variance in signal between different characters.
	\item Bootstrapping helps us assess the variance in $\ln L$ that we would expect to result from sampling error.
\end{itemize}

\myNewSlide
\section*{Summary - Part 2}
\normalsize
A (very) wide variety of tests differ by:
\begin{itemize}
	\item Null hypotheses:
	\begin{compactitem}
		\item Expected scores are the same $\rightarrow$ boundary tests. {\bf Non-parametric tests}
		\item A tree consistent with the null is correct $\rightarrow$ tests that use the full info of the model. {\bf Parametric tests}
	\end{compactitem}
	\item How to use variance information:
	\begin{compactitem}
		\item Rely on ``raw'' bootstrap variability,
		\item Invoke assumptions of normality of scores,
		\item Use $\chi^2$ variants.
	\end{compactitem}
	\item Whether or not the trees must be specified {\em a priori} -- KH Test requires the trees to be specified {\em a priori}.
\end{itemize}

\myNewSlide
\section*{Summary - Part 3}
\large
\begin{table}[htdp]
\begin{center}
\begin{tabular}{|c|p{7cm}|p{6cm}|}
\hline
& Parametric & Nonparametric \\
\hline
$P$-value from $\delta$  & aLRT, aBayes, parametric bootstrapping & KH, SH \\
\hline
$P$-value from BP  &aBP(semi)  & BP, aBP(semi), AU, EHH\\
\hline
\end{tabular}
\end{center}
\label{default}
\end{table}%

When you use a parametric test, you will usually gain power. But non-parametric tests are more robust to model violation.




\myNewSlide
\section*{Significantly different genealogy $\neq$ different phylogeny}
\begin{itemize}
	\item True ``gene tree'' can differ from true ``species tree'' for several biological reasons:
	\begin{itemize}
		\item deep coalescence,
		\item gene duplication/loss (you may be comparing paralogs),
		\item lateral gene transfer.
	\end{itemize}
\end{itemize}

%\includepdf[pages={6-18}]{/home/mtholder/Documents/storage/talks/bodega/HolderSotU.pdf} 

\myNewSlide
\section*{We often don't want to test tree topologies}
\begin{itemize}
	\item If we are conducting a ``comparative method'' we have to consider phylogenetic history,
	\item ideally we would integrate out the uncertainty in the phylogeny,
	\item this entails averaging over trees, but not averaging $P$-values (or point estimates) over trees.
\end{itemize}

%\includepdf[pages={26-27}]{/home/mtholder/Documents/storage/talks/bodega/HolderSotU.pdf} 



\myNewSlide
\section*{Bootstrapping as a noisy measure of repeatability}
\begin{picture}(0,0)(0,0)
	  \put(40,-280){\makebox(0,0)[l]{\includegraphics[scale=1.2]{../newimages/HillisB1993Fig3.pdf}}}
	  \put(150,-330){\small \% recovering tree}
	  \put(0,-20){\small bootstrap}
	  \put(0,-50){\small values from}
	  \put(0,-80){\small many simulations}
	  \put(0,-220){\small repeated}
	  \put(0,-250){\small simulation}
	  \put(390,-170){Simulation study of }
	  \put(390,-200){\citet{HillisB1993} }
\end{picture}


\myNewSlide
\section*{Bootstrap Proportion $\neq$ Posterior Probability}
Several studies have compared the non-parametric bootstrap proportion of clade from an ML analysis of a data set to the posterior probabilities when the same data is analyzed under the same model \citep{SuzukiGN2002,WilcoxZHH2002,AlfaroZL2003,CummingsHMRRW2003,DouadyDBDD2003}.\par

Note: {\em \bf Not} all of these have implied that the measures {\em\bf should} be the same, but some authors have \citep[usually citing][]{EfronHH1996}.

\myNewSlide
\section*{Bootstrap Proportion $\neq$ Posterior Probability in general}
\begin{picture}(-0,0)(-0,0)
	\put(40,-50){\makebox(30,-150)[l]{\includegraphics[scale=2]{/home/mtholder/Documents/ku_teaching/BIOL-848-2013/images/WilcoxZHH-figure.pdf}}}
	\put(40,-330){from \citet{WilcoxZHH2002}}
	\put(40,-380){\normalsize Note: \citet{HuelsenbeckR2004} showed that the Bayesian posterior probabilities}
	\put(40,-400){\normalsize are right on the equality line, if you  simulate from the prior.}
\end{picture}


\myNewSlide
\section*{\citet{Newton1996} showed that, when you look at the median, the BP may not be biased downward}
\begin{picture}(-0,0)(-0,0)
	\put(40,-50){\makebox(30,-150)[l]{\includegraphics[scale=2]{../newimages/Newton1996Fig4.pdf}}}
	\put(40,-330){Figure 4 from \citet{Newton1996}}
\end{picture}

\myNewSlide
\section*{What did \citet{EfronHH1996} say?}
\normalsize
We can use a Bayesian model to show that $\tilde{\alpha}$ is a reasonable 
assessment of the probability that $\mathscr{R}_1$ contains $ \mu$.
Suppose we believe \textit{a priori} that $\mu$ could lie anywhere in the plane with 
equal probability. 
Then having observed $\hat{\mu}$, the \textit{a posteriori} 
distribution of  $\mu$ given  $\hat{\mu}$ is $N_2( \hat{\mu},I)$ exactly the same as the 
bootstrap distribution of $\hat{\mu}^{\ast}$. 
In other words, $\tilde{\alpha}$ is the  \textit{a posteriori}
probability of the event $\mu \in \mathscr{R}_1$, if we begin with an ``uninformative'' prior density for $\mu$.
\begin{picture}(-0,0)(-0,0)
	\put(0,-120){\makebox(30,-150)[l]{\includegraphics[scale=4]{/home/mtholder/Documents/ku_teaching/BIOL-848-2013/images/EfronHH-straight-fig.pdf}}}
\end{picture}

\myNewSlide
\section*{\citet{EfronHH1996} view of tree space}
\begin{picture}(-0,0)(-0,0)
	\put(-10,-90){\makebox(30,-150)[l]{\includegraphics[scale=3]{/home/mtholder/Documents/ku_teaching/BIOL-848-2013/images/EfronHH-treespace-fig.pdf}}}
\end{picture}



\myNewSlide
\section*{What did \citet{EfronHH1996} say (and mean)?}
\begin{itemize}
	\item the ``uninformative'' prior density is a uniform prior over all of pattern frequency space
	\item this is {\em not} equivalent to a prior that would be expected to yield a phylogeny (it is actually identical to the prior you would get if you assumed that all pairwise distances between taxa were $\infty$),
	\item  \citet{EfronHH1996}  were {\em not} predicting that the bootstrap proportions should be identical to those from a Bayesian phylogenetic analysis with real phylogenetic priors.
	\item  \cite{SvennbladEOB2006} have a nice paper on this subject.
\end{itemize}


\myNewSlide
\section*{\citet{Newton1996} provides an intuition for why the mean BP may be lower than repeatability}
\begin{picture}(-0,0)(-0,0)
	\put(40,-50){\makebox(30,-150)[l]{\includegraphics[scale=2]{../newimages/Newton1996Fig3.pdf}}}
	\put(40,-320){Darker ovals indicate probability contours for datasets given the truth}
	\put(60,-350){(note that repeatability $\approx$ 100\%)}
	\put(40,-380){Lighter ovals show probability contours for bootstrapping for one dataset.}
	\put(60,-410){Many real datasets will have BP much $<$ 100\%}
	\put(-40,-50){Figure 3 from \citet{Newton1996}}
\end{picture}



\includepdf[pages={28-45}]{/home/mtholder/Documents/ku_teaching/BIOL-848-2013/lec16-Bootstrapping/lec16Bootstrapping.pdf} 


\end{document}

